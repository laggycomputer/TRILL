{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import esm\n",
    "import torch\n",
    "from argparse import Namespace\n",
    "from esm.constants import proteinseq_toks\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from esm.modules import TransformerLayer, PositionalEmbedding  # noqa\n",
    "from esm.model import ProteinBertModel\n",
    "\n",
    "# model, alphabet = torch.hub.load(\"facebookresearch/esm\", \"esm1_t34_670M_UR50S\")\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ych_util import prepare_mlm_mask\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"../data/VP1s.csv\")\n",
    "dat = dat.sample(frac = 1)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = esm.Alphabet.from_dict(proteinseq_toks)\n",
    "# model_name = \"esm1_t34_670M_UR50S\"\n",
    "model_name = \"esm1_t12_85M_UR50S\"\n",
    "url = f\"https://dl.fbaipublicfiles.com/fair-esm/models/{model_name}.pt\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda\")\n",
    "    model_data = torch.hub.load_state_dict_from_url(url, progress=False)\n",
    "else:\n",
    "    model_data = torch.hub.load_state_dict_from_url(url, progress=False, map_location=torch.device('cpu'))\n",
    "\n",
    "pra = lambda s: ''.join(s.split('decoder_')[1:] if 'decoder' in s else s)\n",
    "prs = lambda s: ''.join(s.split('decoder.')[1:] if 'decoder' in s else s)\n",
    "model_args = {pra(arg[0]): arg[1] for arg in vars(model_data[\"args\"]).items()}\n",
    "model_state = {prs(arg[0]): arg[1] for arg in model_data[\"model\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = esm.ProteinBertModel(\n",
    "        Namespace(**model_args), len(alphabet), padding_idx=alphabet.padding_idx\n",
    "    )\n",
    "\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_converter = alphabet.get_batch_converter()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.0001 # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print_every = 300\n",
    "for j in range(300):\n",
    "    dat = dat.sample(frac = 1)\n",
    "    for i in range(dat.shape[0]):\n",
    "        if len(dat.iloc[i,1])>1024:\n",
    "            seq = dat.iloc[i,1][:1023]\n",
    "        else:\n",
    "            seq = dat.iloc[i,1]\n",
    "        lab = dat.iloc[i,0]\n",
    "        data = [(lab, seq)]\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "        true_aa,target_ind,masked_batch_tokens = prepare_mlm_mask(alphabet,batch_tokens)\n",
    "        optimizer.zero_grad()\n",
    "        results = model(masked_batch_tokens.to('cuda'), repr_layers=[34])   \n",
    "        pred = results[\"logits\"].squeeze(0)[target_ind,:]   \n",
    "        target = true_aa.squeeze(0)\n",
    "        loss = criterion(pred.cpu(),target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % print_every == 1:\n",
    "            print(batch_labels)\n",
    "            print(batch_strs)\n",
    "            print(batch_tokens.size())\n",
    "            print(masked_batch_tokens.size())\n",
    "            print(results[\"logits\"].size())\n",
    "            print(pred.size())\n",
    "            print(target.size())\n",
    "            print(f\"At Epoch: %.1f\"% i)\n",
    "            print(f\"Loss %.4f\"% loss)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"time elapsed %.4f\"% elapsed)\n",
    "            torch.save(model.state_dict(), \"../data/esm_t12_85M_UR50S_vp1s_20211026.pt\")\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../data/esm_t12_85M_UR50S_vp1s_20211026.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
