
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Positional Arguments &#8212; Python  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="embed" href="cmd_embed.html" />
    <link rel="prev" title="Command line utilities" href="cmd.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">trill</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">nodes</span> <span class="n">NODES</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">logger</span> <span class="n">LOGGER</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">profiler</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tune</span><span class="p">]</span>
             <span class="n">name</span> <span class="n">GPUs</span> <span class="p">{</span><span class="n">embed</span><span class="p">,</span><span class="n">finetune</span><span class="p">,</span><span class="n">generate</span><span class="p">,</span><span class="n">fold</span><span class="p">}</span> <span class="o">...</span>
</pre></div>
</div>
<section id="positional-arguments">
<h1>Positional Arguments<a class="headerlink" href="#positional-arguments" title="Permalink to this heading">¶</a></h1>
<dl class="option-list">
<dt><kbd>name</kbd></dt>
<dd><p>Name of run</p>
</dd>
<dt><kbd>GPUs</kbd></dt>
<dd><p>Input total number of GPUs per node</p>
<p>Default: 1</p>
</dd>
<dt><kbd>command</kbd></dt>
<dd><p>Possible choices: embed, finetune, generate, fold</p>
</dd>
</dl>
</section>
<section id="named-arguments">
<h1>Named Arguments<a class="headerlink" href="#named-arguments" title="Permalink to this heading">¶</a></h1>
<dl class="option-list">
<dt><kbd>--nodes</kbd></dt>
<dd><p>Input total number of nodes. Default is 1</p>
<p>Default: 1</p>
</dd>
<dt><kbd>--logger</kbd></dt>
<dd><p>Enable Tensorboard logger. Default is None</p>
<p>Default: False</p>
</dd>
<dt><kbd>--profiler</kbd></dt>
<dd><p>Utilize PyTorchProfiler</p>
<p>Default: False</p>
</dd>
<dt><kbd>--tune</kbd></dt>
<dd><p>Tune TRILL to figure out what models are able to be used on the available hardware</p>
<p>Default: False</p>
</dd>
</dl>
</section>
<section id="Sub-commands">
<h1>Sub-commands<a class="headerlink" href="#Sub-commands" title="Permalink to this heading">¶</a></h1>
<section id="embed">
<h2>embed<a class="headerlink" href="#embed" title="Permalink to this heading">¶</a></h2>
<p>Embed proteins of interest</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trill</span> <span class="n">embed</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">batch_size</span> <span class="n">BATCH_SIZE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">preTrained_model</span> <span class="n">PRETRAINED_MODEL</span><span class="p">]</span>
            <span class="p">[</span><span class="o">--</span><span class="n">model</span> <span class="n">MODEL</span><span class="p">]</span>
            <span class="n">query</span>
</pre></div>
</div>
<section id="positional-arguments_repeat1">
<h3>Positional Arguments<a class="headerlink" href="#positional-arguments_repeat1" title="Permalink to this heading">¶</a></h3>
<dl class="option-list">
<dt><kbd>query</kbd></dt>
<dd><p>Input fasta file</p>
</dd>
</dl>
</section>
<section id="named-arguments_repeat1">
<h3>Named Arguments<a class="headerlink" href="#named-arguments_repeat1" title="Permalink to this heading">¶</a></h3>
<dl class="option-list">
<dt><kbd>--batch_size</kbd></dt>
<dd><p>Change batch-size number for embedding proteins. Default is 1</p>
<p>Default: 1</p>
</dd>
<dt><kbd>--preTrained_model</kbd></dt>
<dd><p>Input path to your own pre-trained ESM model</p>
<p>Default: False</p>
</dd>
<dt><kbd>--model</kbd></dt>
<dd><p>Change model. Default is esm2_t12_35M_UR50D. You can choose either ProtGPT2 or various ESM2. List of ESM2 models can be found at <a class="reference external" href="https://github.com/facebookresearch/esm">https://github.com/facebookresearch/esm</a></p>
<p>Default: “esm2_t12_35M_UR50D”</p>
</dd>
</dl>
</section>
</section>
<section id="finetune">
<h2>finetune<a class="headerlink" href="#finetune" title="Permalink to this heading">¶</a></h2>
<p>Fine-tune models</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trill</span> <span class="n">finetune</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">query</span> <span class="n">QUERY</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">epochs</span> <span class="n">EPOCHS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">lr</span> <span class="n">LR</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">model</span> <span class="n">MODEL</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">LEGGO</span><span class="p">]</span>
               <span class="p">[</span><span class="o">--</span><span class="n">batch_size</span> <span class="n">BATCH_SIZE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">strategy</span> <span class="n">STRATEGY</span><span class="p">]</span>
</pre></div>
</div>
<section id="named-arguments_repeat2">
<h3>Named Arguments<a class="headerlink" href="#named-arguments_repeat2" title="Permalink to this heading">¶</a></h3>
<dl class="option-list">
<dt><kbd>--query</kbd></dt>
<dd><p>Input fasta file</p>
</dd>
<dt><kbd>--epochs</kbd></dt>
<dd><p>Number of epochs for fine-tuning. Default is 20</p>
<p>Default: 20</p>
</dd>
<dt><kbd>--lr</kbd></dt>
<dd><p>Learning rate for optimizer. Default is 0.0001</p>
<p>Default: 0.0001</p>
</dd>
<dt><kbd>--model</kbd></dt>
<dd><p>Change model. Default is esm2_t12_35M_UR50D. You can choose either ProtGPT2 or various ESM2. List of ESM2 models can be found at <a class="reference external" href="https://github.com/facebookresearch/esm">https://github.com/facebookresearch/esm</a></p>
<p>Default: “esm2_t12_35M_UR50D”</p>
</dd>
<dt><kbd>--LEGGO</kbd></dt>
<dd><p>deepspeed_stage_3_offload.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--batch_size</kbd></dt>
<dd><p>Change batch-size number for fine-tuning. Default is 1</p>
<p>Default: 1</p>
</dd>
<dt><kbd>--strategy</kbd></dt>
<dd><p>Change training strategy. Default is None. List of strategies can be found at <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/strategy.html">https://pytorch-lightning.readthedocs.io/en/stable/extensions/strategy.html</a></p>
</dd>
</dl>
</section>
</section>
<section id="generate">
<h2>generate<a class="headerlink" href="#generate" title="Permalink to this heading">¶</a></h2>
<p>Generate proteins using either ESM-IF1 or ProtGPT2</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trill</span> <span class="n">generate</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">finetuned_protgpt2</span> <span class="n">FINETUNED_PROTGPT2</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">temp</span> <span class="n">TEMP</span><span class="p">]</span>
               <span class="p">[</span><span class="o">--</span><span class="n">genIters</span> <span class="n">GENITERS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">seed_seq</span> <span class="n">SEED_SEQ</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">max_length</span> <span class="n">MAX_LENGTH</span><span class="p">]</span>
               <span class="p">[</span><span class="o">--</span><span class="n">do_sample</span> <span class="n">DO_SAMPLE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">top_k</span> <span class="n">TOP_K</span><span class="p">]</span>
               <span class="p">[</span><span class="o">--</span><span class="n">repetition_penalty</span> <span class="n">REPETITION_PENALTY</span><span class="p">]</span>
               <span class="p">[</span><span class="o">--</span><span class="n">num_return_sequences</span> <span class="n">NUM_RETURN_SEQUENCES</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">query</span> <span class="n">QUERY</span><span class="p">]</span>
               <span class="p">{</span><span class="n">ESM</span><span class="o">-</span><span class="n">IF1</span><span class="p">,</span><span class="n">ProtGPT2</span><span class="p">}</span>
</pre></div>
</div>
<section id="positional-arguments_repeat2">
<h3>Positional Arguments<a class="headerlink" href="#positional-arguments_repeat2" title="Permalink to this heading">¶</a></h3>
<dl class="option-list">
<dt><kbd>model</kbd></dt>
<dd><p>Possible choices: ESM-IF1, ProtGPT2</p>
<p>Choose between Inverse Folding model ‘esm_if1_gvp4_t16_142M_UR50’ to facilitate fixed backbone sequence design or ProtGPT2.</p>
</dd>
</dl>
</section>
<section id="named-arguments_repeat3">
<h3>Named Arguments<a class="headerlink" href="#named-arguments_repeat3" title="Permalink to this heading">¶</a></h3>
<dl class="option-list">
<dt><kbd>--finetuned_protgpt2</kbd></dt>
<dd><p>Input path to your own finetuned ProtGPT2 model</p>
<p>Default: False</p>
</dd>
<dt><kbd>--temp</kbd></dt>
<dd><p>Choose sampling temperature for ESM_IF1.</p>
<p>Default: 1.0</p>
</dd>
<dt><kbd>--genIters</kbd></dt>
<dd><p>Choose sampling iteration number for ESM_IF1.</p>
<p>Default: 1</p>
</dd>
<dt><kbd>--seed_seq</kbd></dt>
<dd><p>Sequence to seed ProtGPT2 Generation</p>
<p>Default: “M”</p>
</dd>
<dt><kbd>--max_length</kbd></dt>
<dd><p>Max length of proteins generated from ProtGPT2</p>
<p>Default: 333</p>
</dd>
<dt><kbd>--do_sample</kbd></dt>
<dd><p>Whether or not to use sampling for ProtGPT2 ; use greedy decoding otherwise</p>
<p>Default: True</p>
</dd>
<dt><kbd>--top_k</kbd></dt>
<dd><p>The number of highest probability vocabulary tokens to keep for top-k-filtering for ProtGPT2</p>
<p>Default: 950</p>
</dd>
<dt><kbd>--repetition_penalty</kbd></dt>
<dd><p>The parameter for repetition penalty for ProtGPT2. 1.0 means no penalty</p>
<p>Default: 1.2</p>
</dd>
<dt><kbd>--num_return_sequences</kbd></dt>
<dd><p>Number of sequences for ProtGPT2 to generate. Default is 5</p>
<p>Default: 5</p>
</dd>
<dt><kbd>--query</kbd></dt>
<dd><p>Input pdb or cif file for inverse folding with ESM_IF1</p>
</dd>
</dl>
</section>
</section>
<section id="fold">
<h2>fold<a class="headerlink" href="#fold" title="Permalink to this heading">¶</a></h2>
<p>Predict 3D protein structures using ESMFold</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trill</span> <span class="n">fold</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="n">query</span>
</pre></div>
</div>
<section id="positional-arguments_repeat3">
<h3>Positional Arguments<a class="headerlink" href="#positional-arguments_repeat3" title="Permalink to this heading">¶</a></h3>
<dl class="option-list">
<dt><kbd>query</kbd></dt>
<dd><p>Input fasta file</p>
</dd>
</dl>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Python</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="cmd.html">Command line utilities</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Positional Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#named-arguments">Named Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Sub-commands">Sub-commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="cmd_embed.html">embed</a></li>
<li class="toctree-l2"><a class="reference internal" href="cmd_finetune.html">finetune</a></li>
<li class="toctree-l2"><a class="reference internal" href="cmd_generate.html">generate</a></li>
<li class="toctree-l2"><a class="reference internal" href="cmd_fold.html">fold</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="cmd.html">Command line utilities</a><ul>
      <li>Previous: <a href="cmd.html" title="previous chapter">Command line utilities</a></li>
      <li>Next: <a href="cmd_embed.html" title="next chapter">embed</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.1.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/cmd_main.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>